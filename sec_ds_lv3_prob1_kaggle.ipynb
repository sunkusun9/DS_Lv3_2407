{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "765c0422",
   "metadata": {},
   "source": [
    "# 문제 6\n",
    "\n",
    "[Kaggle 형] train_prob.csv로 문제 failure 예측하는 모델을 만들고, \n",
    "\n",
    "test_prob.csv에 대한 failure가 1일 확률 예측하여 다음과 같은 형식의 answer6.csv를 만들어라. \n",
    "\n",
    "측정 지표는 AUC(area under of ROC curve)이다. id 는 테스트 케이스의 id 이고, failure에는 failure가 1이 될 확률이다.\n",
    "\n",
    "id,failure\n",
    "\n",
    "16115, 0.1\n",
    "\n",
    "16116, 0.2\n",
    "\n",
    "\n",
    "**강사: 멀티캠퍼스 강선구(sunku0316.kang@multicampus.com, sun9sun9@gmail.com)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42ff1fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.4 (tags/v3.7.4:e09359112e, Jul  8 2019, 20:34:20) [MSC v.1916 64 bit (AMD64)]\n",
      "pandas 0.25.1\n",
      "numpy 1.18.5\n",
      "sklearn 0.21.3\n",
      "scipy 1.5.2\n",
      "mlxtend 0.15.0.0\n",
      "statsmodels 0.11.1\n",
      "xgboost 0.80\n"
     ]
    }
   ],
   "source": [
    "# 실행 환경 확인\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import scipy\n",
    "import statsmodels\n",
    "#pip install --upgrade mlxtend \n",
    "import mlxtend\n",
    "import sys\n",
    "import xgboost as xgb\n",
    "\n",
    "print(sys.version)\n",
    "for i in [pd, np, sklearn, scipy, mlxtend, statsmodels, xgb]:\n",
    "    print(i.__name__, i.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "583486de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train_prob.csv', index_col=['id'])\n",
    "df_test = pd.read_csv('test_prob.csv', index_col=['id'])\n",
    "# 실제시험 x\n",
    "s_ans = pd.read_csv('test_prob_ans.csv', index_col=['id'])['failure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "488c6d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.assign(\n",
    "    na_1 = lambda x: x['measurement_3'].isna(),\n",
    "    na_2 = lambda x: x['measurement_5'].isna(),\n",
    ")\n",
    "df_test = df_test.assign(\n",
    "    na_1 = lambda x: x['measurement_3'].isna(),\n",
    "    na_2 = lambda x: x['measurement_5'].isna(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c3bb724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "# 방법 2: groupby ~ apply ~ fit_transform\n",
    "# product_code 별로 IterativeImputer를 통한 결측처리를 하고 바로 적용합니다.\n",
    "imp  = IterativeImputer(\n",
    "    estimator=LinearRegression(fit_intercept=True), \n",
    "    random_state=123\n",
    ")\n",
    "X_imp = ['measurement_{}'.format(i) for i in range(3, 10)] + ['measurement_17']\n",
    "\n",
    "# apply에서 transform에서 numpy array를 넘겨 주므로, \n",
    "# DataFrame을 만들어 반환시켜주면,\n",
    "# apply에서 DataFrame으로 재구성하여 넘겨줍니다.\n",
    "# 모델을 적용하여 결측이 처리된 데이터프레임을 만듭니다.\n",
    "df_train[X_imp] = df_train.groupby('product_code')[X_imp].apply(\n",
    "    lambda x: pd.DataFrame(imp.fit_transform(x), index=x.index, columns=X_imp)\n",
    ")\n",
    "df_test[X_imp] = df_test.groupby('product_code')[X_imp].apply(\n",
    "    lambda x: pd.DataFrame(imp.fit_transform(x), index=x.index, columns=X_imp)\n",
    ")\n",
    "\n",
    "# 방법 3: groupby ~ transform\n",
    "# Transform을 통해 수준별 평균으로 1:1 변환된 값으로 구성된 DataFrame을 받아서, \n",
    "# 각각의 요소별로 결측이면 해당값으로 치환되게 구성합니다. \n",
    "X_mean = ['measurement_{}'.format(i) for i in range(10, 17)]\n",
    "df_train[X_mean] =  df_train.groupby('product_code')[X_mean].transform(\n",
    "    lambda x: x.fillna(x.mean())\n",
    ")\n",
    "df_test[X_mean] =  df_test.groupby('product_code')[X_mean].transform(\n",
    "    lambda x: x.fillna(x.mean())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b54c265",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['loading'] = df_train['loading'].fillna(df_train['loading'].mean())\n",
    "df_test['loading'] = df_test['loading'].fillna(df_train['loading'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d05ff297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "D    5112\n",
       "Name: product_code, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['product_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e303531e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C    5765\n",
       "E    5343\n",
       "B    5250\n",
       "A    5100\n",
       "Name: product_code, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['product_code'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e519b6",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- loading의 각 행들에 자연 로그 함수를 적용하여 파생 변수 loading_log를 만든다.\n",
    "\n",
    "- LR + SFS: \\['loading', 'measurement_1', 'measurement_4', 'measurement_14', 'measurement_17', 'na_1'\\] 최적 변수\n",
    "\n",
    "- LDA: transform / predict\n",
    "\n",
    "- LR + PCA: n_components=7 + 'loading'\n",
    "\n",
    "- RF: {'n_estimators': 15, 'max_depth': 7, 'min_samples_split': 512}, ['loading'] + ['measurement_{}'.format(i) for i in range(18)] + ['na_1', 'na_2']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b12505",
   "metadata": {},
   "source": [
    "# Kaggle형 풀이 단계\n",
    "\n",
    "Step 1: 검증 방법을 정하고, 검증 루틴을 만듭니다.\n",
    "\n",
    "Step 2: Baseline 모델을 만듭니다\n",
    "\n",
    "Step 3: 모델 선택 루틴을 만듭니다.\n",
    "\n",
    "Step 4: 모델 개선 작업을 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9c1c406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A' 'B' 'E'] ['C']\n",
      "['A' 'B' 'C'] ['E']\n",
      "['A' 'C' 'E'] ['B']\n",
      "['B' 'C' 'E'] ['A']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold, cross_validate\n",
    "\n",
    "gcv = GroupKFold(n_splits=4)\n",
    "for train_idx, valid_idx in gcv.split(df_train, df_train['failure'], groups=df_train['product_code']):\n",
    "    print(\n",
    "        df_train.iloc[train_idx]['product_code'].unique(), \n",
    "        df_train.iloc[valid_idx]['product_code'].unique()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1fc621c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.0404253 , 0.02318096, 0.03029585, 0.04003239]),\n",
       " 'score_time': array([0.00387049, 0.01046252, 0.        , 0.        ]),\n",
       " 'test_score': array([0.58823117, 0.58496642, 0.58887652, 0.59535198]),\n",
       " 'train_score': array([0.59259755, 0.5935028 , 0.59192673, 0.58955959])}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "cross_validate(\n",
    "    make_pipeline(StandardScaler(), LogisticRegression(solver='lbfgs')),\n",
    "    df_train[['loading', 'measurement_1', 'measurement_4', 'measurement_14', 'measurement_17', 'na_1']],\n",
    "    df_train['failure'],\n",
    "    cv = gcv,\n",
    "    groups=df_train['product_code'], \n",
    "    scoring='roc_auc',\n",
    "    return_train_score=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4f7985",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
